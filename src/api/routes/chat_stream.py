"""æµå¼å¯¹è¯æ¥å£è·¯ç”±ï¼ˆåŸºäº Callbacksï¼‰"""

from datetime import datetime
from typing import AsyncGenerator, Any, Dict, List
import asyncio
import json
import re
from queue import Queue

from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from langchain_core.callbacks import BaseCallbackHandler

from src.agent.devops_agent import DevOpsAgent
from src.models.schemas import ChatRequest, AGUIRunAgentInput
from src.utils.logger import get_logger
from src.utils.agui_adapter import AGUIAdapter

logger = get_logger(__name__)
router = APIRouter(tags=["å¯¹è¯"])


def clean_model_output(text: str) -> str:
    """æ¸…ç†æ¨¡å‹è¾“å‡ºä¸­çš„ç‰¹æ®Šæ ‡ç­¾

    ç§»é™¤ XML æ ‡ç­¾ï¼ˆ<think>, </think>ï¼‰å’Œå…¶ä»–å¯èƒ½å½±å“ UI æ˜¾ç¤ºçš„æ ‡è®°

    Args:
        text: åŸå§‹æ–‡æœ¬

    Returns:
        æ¸…ç†åçš„æ–‡æœ¬
    """
    if not text:
        return text

    # ç§»é™¤ <think> å’Œ </think> æ ‡ç­¾
    text = re.sub(r'</?think>', '', text, flags=re.IGNORECASE)

    # ç§»é™¤å…¶ä»–å¸¸è§çš„ XML æ ‡ç­¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
    # text = re.sub(r'<[^>]+>', '', text)

    return text


class StreamingCallbackHandler(BaseCallbackHandler):
    """æµå¼å›è°ƒå¤„ç†å™¨

    æ•è· Agent æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å„ç§äº‹ä»¶å¹¶æ”¾å…¥é˜Ÿåˆ—ã€‚
    """

    def __init__(self, queue: Queue):
        self.queue = queue

    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> None:
        """LLM å¼€å§‹"""
        self.queue.put({"type": "thinking", "content": "æ­£åœ¨æ€è€ƒ..."})

    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        """LLM ç”Ÿæˆæ–° token - å®ç°é€å­—æ˜¾ç¤º

        ğŸ”¥ æ”¯æŒ reasoning_contentï¼š
        - å¦‚æœ chunk ä¸­åŒ…å« reasoning_contentï¼Œå‘é€ reasoning_token äº‹ä»¶
        - å¦‚æœåŒ…å« contentï¼Œå‘é€æ™®é€š token äº‹ä»¶
        """
        # è·å– chunk å¯¹è±¡
        chunk = kwargs.get('chunk')

        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰ reasoning content
        if chunk:
            # chunk æ˜¯ ChatGenerationChunkï¼Œmessage æ˜¯ AIMessageChunk
            if hasattr(chunk, 'message'):
                msg = chunk.message
                # æ£€æŸ¥ additional_kwargs ä¸­çš„ reasoning_content
                if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs:
                    reasoning = msg.additional_kwargs.get('reasoning_content')
                    if reasoning:
                        # ğŸ”¥ æ¸…ç† reasoning content ä¸­çš„ XML æ ‡ç­¾
                        cleaned_reasoning = clean_model_output(reasoning)
                        # å‘é€ reasoning token äº‹ä»¶
                        self.queue.put({
                            "type": "reasoning_token",
                            "content": cleaned_reasoning
                        })
                        return  # reasoning token ä¸éœ€è¦å†å‘é€æ™®é€š token

        # ğŸ”¥ æ¸…ç†æ™®é€š token ä¸­çš„ XML æ ‡ç­¾
        cleaned_token = clean_model_output(token)
        # å‘é€æ™®é€š content token
        self.queue.put({
            "type": "token",
            "content": cleaned_token
        })

    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs: Any) -> None:
        """å·¥å…·è°ƒç”¨å¼€å§‹"""
        tool_name = serialized.get("name", "unknown")
        self.queue.put({
            "type": "tool_start",
            "tool": tool_name,
            "input": input_str[:200]
        })

    def on_tool_end(self, output: str, **kwargs: Any) -> None:
        """å·¥å…·è°ƒç”¨ç»“æŸ"""
        self.queue.put({
            "type": "tool_end",
            "output": output[:200]
        })

    def on_agent_action(self, action: Any, **kwargs: Any) -> None:
        """Agent è¡ŒåŠ¨"""
        self.queue.put({
            "type": "action",
            "action": action.tool,
            "thought": action.log[:300] if hasattr(action, 'log') else ""
        })

    def on_agent_finish(self, finish: Any, **kwargs: Any) -> None:
        """Agent å®Œæˆ"""
        output = finish.return_values.get("output", "") if hasattr(finish, 'return_values') else ""
        self.queue.put({
            "type": "done",
            "response": output
        })


async def stream_with_callback(agent: DevOpsAgent, message: str, session_id: str) -> AsyncGenerator[str, None]:
    """ä½¿ç”¨å›è°ƒçš„æµå¼è¿”å›ï¼ˆAG-UI åè®®ï¼‰"""
    queue = Queue()

    try:
        # åˆ›å»º AG-UI é€‚é…å™¨
        adapter = AGUIAdapter(session_id=session_id)

        # å‘é€ä¼šè¯å¼€å§‹äº‹ä»¶
        start_events = adapter.convert_event({"type": "start", "session_id": session_id or "new"})
        for event in start_events:
            yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"

        # åˆ›å»ºå›è°ƒå¤„ç†å™¨
        callback = StreamingCallbackHandler(queue)

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œ Agent
        def run_agent():
            try:
                executor, sid, memory = agent.create_executor(session_id)

                # æ·»åŠ å›è°ƒ
                result = executor.invoke(
                    {"input": message},
                    config={"callbacks": [callback]}
                )

                # æ”¾å…¥æœ€ç»ˆç»“æœ
                queue.put({
                    "type": "final",
                    "response": result.get("output", ""),
                    "session_id": sid
                })

            except Exception as e:
                queue.put({"type": "error", "error": str(e)})
            finally:
                queue.put(None)  # ç»“æŸæ ‡è®°

        # å¯åŠ¨åå°çº¿ç¨‹
        import threading
        thread = threading.Thread(target=run_agent)
        thread.start()

        # ä»é˜Ÿåˆ—è¯»å–å¹¶æµå¼å‘é€
        while True:
            await asyncio.sleep(0.1)  # é¿å…CPUå ç”¨è¿‡é«˜

            while not queue.empty():
                event = queue.get()

                if event is None:  # ç»“æŸæ ‡è®°
                    return

                # ğŸ”¥ é€šè¿‡ AG-UI é€‚é…å™¨è½¬æ¢äº‹ä»¶
                agui_events = adapter.convert_event(event)

                # å‘é€è½¬æ¢åçš„äº‹ä»¶ï¼ˆå¯èƒ½æ˜¯å¤šä¸ªï¼‰
                for agui_event in agui_events:
                    yield f"data: {json.dumps(agui_event, ensure_ascii=False)}\n\n"

    except Exception as e:
        logger.error(f"æµå¼å“åº”é”™è¯¯: {str(e)}")
        # å‘é€é”™è¯¯äº‹ä»¶
        error_events = adapter.convert_event({"type": "error", "error": str(e)})
        for event in error_events:
            yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"


@router.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """æµå¼å¯¹è¯æ¥å£ï¼ˆAG-UI åè®®ï¼‰- ç®€åŒ–æ ¼å¼

    ç¬¦åˆ AG-UI åè®®æ ‡å‡†çš„æµå¼ SSE æ¥å£ï¼Œæ”¯æŒ TDesign Chat ç»„ä»¶ç›´æ¥é›†æˆã€‚

    AG-UI äº‹ä»¶ç±»å‹ï¼š
    - RUN_STARTED/FINISHED/ERROR: ä¼šè¯ç”Ÿå‘½å‘¨æœŸ
    - THINKING_*: æ€è€ƒè¿‡ç¨‹ï¼ˆDeepseek Reasoningï¼‰
    - TEXT_MESSAGE_*: æ­£å¼å›ç­”å†…å®¹
    - TOOL_CALL_*: å·¥å…·è°ƒç”¨è¿‡ç¨‹

    å‰ç«¯é›†æˆç¤ºä¾‹ï¼ˆVue3 + TDesign Chatï¼‰ï¼š
    ```vue
    <template>
      <t-chatbot :chat-service-config="chatServiceConfig" />
    </template>

    <script setup>
    const chatServiceConfig = {
      endpoint: '/api/v1/chat/stream',
      protocol: 'agui',  // å¯ç”¨ AG-UI åè®®
      stream: true,
    };
    </script>
    ```

    æˆ–ä½¿ç”¨åŸç”Ÿ EventSourceï¼š
    ```javascript
    const eventSource = new EventSource('/api/v1/chat/stream');
    eventSource.onmessage = (event) => {
        const data = JSON.parse(event.data);
        console.log(data.type, data);
    };
    ```

    æˆ–ä½¿ç”¨ curl æµ‹è¯•ï¼š
    ```bash
    curl -N -X POST http://localhost:8000/api/v1/chat/stream \\
      -H "Content-Type: application/json" \\
      -d '{"message": "æŸ¥è¯¢é¡¹ç›®çŠ¶æ€", "session_id": null}'
    ```
    """
    agent = DevOpsAgent()

    return StreamingResponse(
        stream_with_callback(agent, request.message, request.session_id),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


@router.post("/agent/run")
async def agent_run(request: AGUIRunAgentInput):
    """AG-UI åè®®æ ‡å‡†ç«¯ç‚¹ (RunAgentInput)

    å®Œå…¨ç¬¦åˆ AG-UI åè®®æ ‡å‡†çš„æ¥å£ï¼Œæ¥æ”¶ RunAgentInput æ ¼å¼è¯·æ±‚ã€‚

    è¯·æ±‚æ ¼å¼ï¼š
    ```json
    {
      "threadId": "thread-123",
      "runId": "run-456",
      "messages": [
        {"role": "user", "content": "ä½ å¥½"},
        {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ"},
        {"role": "user", "content": "è¯·å¸®æˆ‘æ£€æŸ¥Navigationé¡¹ç›®çš„ä»£ç è¦†ç›–ç‡"}
      ],
      "tools": [...],
      "state": {...},
      "context": {...}
    }
    ```

    è¿”å›ï¼šAG-UI æ ‡å‡†äº‹ä»¶æµ (SSE)

    å‰ç«¯é›†æˆç¤ºä¾‹ï¼ˆTDesign Chatï¼‰ï¼š
    ```vue
    <script setup>
    const chatServiceConfig = {
      endpoint: '/api/v1/agent/run',
      protocol: 'agui',
      stream: true,
    };
    </script>
    ```
    """
    # ğŸ”¥ æ‰“å°æˆåŠŸè§£æçš„è¯·æ±‚æ•°æ®
    logger.info("=" * 80)
    logger.info("[SUCCESS] /agent/run request parsed")
    logger.info(f"  threadId: {request.threadId}")
    logger.info(f"  runId: {request.runId}")
    logger.info(f"  messages count: {len(request.messages)}")
    for i, msg in enumerate(request.messages):
        logger.info(f"    [{i}] role={msg.role}, content={msg.content[:50]}...")
    logger.info("=" * 80)

    agent = DevOpsAgent()

    # æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    user_messages = [msg for msg in request.messages if msg.role == "user"]
    if not user_messages:
        # å¦‚æœæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›é”™è¯¯
        logger.warning("è¯·æ±‚ä¸­æ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯")
        async def error_stream():
            yield f"data: {json.dumps({'type': 'RUN_ERROR', 'error': 'No user message found'}, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            error_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    last_user_message = user_messages[-1].content
    logger.info(f"æå–çš„ç”¨æˆ·æ¶ˆæ¯: {last_user_message}")

    # ä½¿ç”¨ threadId ä½œä¸º session_id
    session_id = request.threadId or request.runId

    return StreamingResponse(
        stream_with_callback(agent, last_user_message, session_id),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )
